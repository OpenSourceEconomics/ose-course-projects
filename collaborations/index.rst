Collaboration projects
======================

We set up collaboration projects with our partners from the private sector. These allow students to directly put the skills acquired during class into action, gain hands-on experience in a professional data science setting, and receive feedback and mentoring from seasoned data scientists. We announce collaboration projects in class and also discuss there how to apply.

Daimler AG
----------

**What is the project about?**

The project is about finding (and applying) methods to identify anomalies and abnormal observations in production processes. Provided with datasets by Daimler AG, the task of the student is to explore the datasets and their respective structures and based on these insights, choose appropriate methods to conduct anomaly analysis, i.e., find (groups of) observations that differ significantly from the normal case.

**What is the scope of the project?**

The main focus of this project is to compare different methods and to discuss the advantages and disadvantages with respect to their theoretical assumptions and their practical implications (e.g., computational costs). In this context, it is noteworthy that Daimler AG is interested in applying the methods provided by the student to different datasets after the project has been submitted. Consequently, reproducibility and setting up a flexible data workflow is a core requirement of the project. While guiding literature is provided, the choice of the methods is up to the student. Therefore, methods applied can range from traditional econometric time series analysis to the application of machine- and deep learning techniques.

**Why should I be interested?**

Overall, the project enables the student to learn about the use cases of data analysis in a corporate environment and get hands-on experience in professional data science. Through supervising meetings with Daimler AG the student has additionally the chance to get feedback and insights from professional data scientists and learn about their work.


Deutsche Bank
--------------

**What is the project about?**

The project main concern is to use modern Machine Learning (ML) methods to detect so-called regret credits, with data sets provided by Deutsche Bank AG. The idea is to prepare final data sets that provide useful information for choosing methods to assign probability of delinquency of these type of credits. In some cases, multiple learning algorithms are used to obtain better predictive performance, specially if certain methods provide better results on specific cases. Moreover, data visualizations are performed to support the content of the data and results to finally present them to the stakeholders.

**What is the scope of the project?**

The projectâ€™s scope is to develop an AI-related model that can determine the probability of credit deficiencies and allocate this probability to certain characteristics (e.g. civil status, credit coverage rate, etc.). Several ML methods will be developed and compared to build a model based on the performance and precision of the results. Logically, the methods that perform the best will also be considered in the final model since they provide the most accurate results. This project will be very programming-heavy and model-oriented. Also, the project will also address "explainable AI", a topic highly debated in the scientific community. The goal will be to shed light on the so-called black-box, where even the AI developers do not know why their AIs make certain decisions and exhibit certain behavior patterns. In the end, the decision of the AI that a certain credit has a certain probability of being conspicuous shall be understood better. The other main challenge is that the data set is imbalanced. That is, it contains many more non-regret credits than regret credits. This has to be taken into account in the model development. A simple accuracy score is not sufficient to determine the quality of the model's prediction, since probably 90% of the credits reflect non-regret cases and a 100% non-regret decision would achieve just that very accurate precision.

**Why should I be interested?**

First, it is important to understand how AI comes to certain results and how they behave. As AI becomes more advanced, humans are challenged to understand their decisions. Explainability can help developers ensure that the system is working as expected, it might be necessary to meet regulatory standards, or it might be important in allowing those affected by a decision to challenge or change that outcome. This explainability is also relevant concerning social issues. For example, there is a well-known scandal in the field of crime risk assessment, in which the COMPAS software was used across the US to predict future criminals. As it appears from this article, the software that uses ML is biased against blacks. This could possibly be prevented by increasing the transparency of the so-called black box.

Second, I put a lot of emphasis on understanding the data imbalance problem better and how to approach better results in the ML world, since the data imbalance problem has caused me a lot of frustration in previous work. Moreover, efficient classification with imbalanced data is an important part of science as well, as imbalanced data can be found in many real-world applications, e.g. cancer detection. And, as mentioned in the paper "Survey on deep learning with class imbalance" written by Johnson and Khoshgoftaar (2019), very little empirical work in the area of deep learning with class imbalance exists although there were recent advances in deep learning, along with its increasing popularity. Therefore, I believe that there is still a lot to get out of it.

Finally, I am personally very interested in the topic of modern ML methods, especially related to the banking world and risk + uncertainty quantification. Banks are subject to many guidelines and have to justify lending decisions, so developing such a model coupled with the issue of explainability is particularly innovative and futuristic for the banking sector. From the perspective that ML methods are still rarely used in the banking world, but are commonplace in the Silicon Valley world, I look forward to contributing to a potential migration of futuristic methods in the banking world. Besides, I am generally convinced that ML will later become very important in numerous disciplines and is comparatively still very unexplored (although many ML algorithms have been around for a long time). Therefore, I would like to contribute to it.

The above points basically leave me no choice but to be interested in this topic.
